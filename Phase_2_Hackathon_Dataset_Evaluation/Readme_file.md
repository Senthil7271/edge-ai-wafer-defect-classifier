# ğŸ”¬ğŸ§  Edge-AI Wafer Defect Classification â€” Phase 2 (ONNX Inference)

![Python](https://img.shields.io/badge/Python-3.10+-blue)
![Framework](https://img.shields.io/badge/Framework-TensorFlow-orange)
![Model](https://img.shields.io/badge/Backbone-MobileNetV2-green)
![Export](https://img.shields.io/badge/Export-ONNX-blueviolet)
![Inference](https://img.shields.io/badge/Inference-ONNX%20Runtime-yellow)
![Input](https://img.shields.io/badge/Input-Grayscale-lightgrey)
![Target](https://img.shields.io/badge/Target-Edge%20AI-brightgreen)
![Phase](https://img.shields.io/badge/Phase-2%20Evaluation-blue)

---

# ğŸ“Œ Phase 2 Overview

Phase 2 evaluates the exported ONNX model on the provided hackathon test dataset.

This stage validates:

â€¢ ONNX inference pipeline  
â€¢ Preprocessing consistency  
â€¢ Class index alignment  
â€¢ Multi-class evaluation metrics  
â€¢ Confusion matrix generation  

---




---

# ğŸ§¬ Test Dataset Classes (Phase 2)

The provided test dataset contains 9 classes:

â€¢ Bridge  
â€¢ Clean  
â€¢ cmp  
â€¢ Cracks  
â€¢ LER  
â€¢ open  
â€¢ other  
â€¢ particle contamination  
â€¢ via  

âš  Note: The "Stain" class is not present in the Phase 2 test dataset.

Evaluation was performed strictly on the available classes.

---

# ğŸ“Š Phase 2 Test Results

**Test Samples:** 296  

## ğŸ¯ Overall Performance

| Metric | Score |
|--------|-------|
| Accuracy | ~26% |
| Micro F1 | ~0.25 |
| Macro F1 | ~0.25 |
| Weighted F1 | ~0.23 |

---

## ğŸ“ˆ Per-Class Performance Snapshot

| Class | F1 Score |
|--------|----------|
| Bridge | 0.22 |
| CMP | 0.38 |
| Clean | 0.28 |
| Crack | 0.44 |
| LER | 0.26 |
| Open | 0.24 |
| Other | 0.00 |
| Particle | 0.26 |
| VIA | 0.16 |

---

# ğŸ” Observations

âœ” Performance above random baseline (~11% for 9 classes)  
âœ” Stronger predictions in CMP and Crack  
âœ” Low recall observed for "Other"  
âœ” Class overlap between crack/open/bridge patterns  
âœ” Realistic multi-class classification challenge  

---

# ğŸ“Š Confusion Matrix

Generated using ONNX Runtime inference:

![Confusion Matrix](phase2_confusion_matrix.png)

Highlights:

â€¢ Diagonal dominance in certain classes  
â€¢ Misclassification concentrated in similar defect types  
â€¢ â€œOtherâ€ class shows significant confusion 

ğŸ” Important Observation on â€œOtherâ€ Class

The â€œOtherâ€ class shows very low recall.

Analysis indicates that several images labeled as â€œOtherâ€ in the Phase 2 test dataset visually resemble specific defect categories used during training.

As a result:

The model tends to classify those samples into structured defect classes (e.g., Crack, CMP, Open)

This leads to reduced recall for â€œOtherâ€

The behavior reflects dataset label overlap rather than model instability

This observation is important for interpreting Phase 2 evaluation metrics.
---

# âš™ Technical Details

| Component | Used |
|------------|------|
| Inference Engine | ONNX Runtime |
| Input Shape | (224,224,1) |
| Data Format | NHWC |
| Training Framework | TensorFlow + Keras |
| Backbone | MobileNetV2 |
| Batch Size | 32 |

---

# ğŸ“¦ Edge Deployment Status

âœ” ONNX export successful  
âœ” CPU inference supported  
âœ” Edge-ready format  
âœ” Lightweight deployment footprint  

| Artifact | Size |
|----------|------|
| Keras Model | 26 MB |
| ONNX Model | 9 MB |

---



---

# â–¶ï¸ Run Phase 2 Evaluation

Install dependencies:



pip install -r requirements.txt


Run inference:



python hackathon_test_dataset_prediction.py


Outputs generated:

â€¢ prediction_log.txt  
â€¢ phase2_confusion_matrix.png  

---

# ğŸš€ Conclusion

The ONNX inference pipeline was successfully validated under Phase 2 conditions.

â€¢ Multi-class defect detection confirmed  
â€¢ Edge-compatible deployment achieved  
â€¢ Evaluation metrics computed under real dataset constraints  

The system is ready for further optimization, retraining, or hardware deployment.

---

If helpful, consider giving this repository a â­
